Service Design Specification
fintrack-expensemanagement-service documentation Version: 1.0.1

Scope
This document provides a structured architectural overview of the expenseManagement microservice, detailing its configuration, data model, authorization logic, business rules, and API design. It has been automatically generated based on the service definition within Mindbricks, ensuring that the information reflects the source of truth used during code generation and deployment.

The document is intended to serve multiple audiences:

Service architects can use it to validate design decisions and ensure alignment with broader architectural goals.
Developers and maintainers will find it useful for understanding the structure and behavior of the service, facilitating easier debugging, feature extension, and integration with other systems.
Stakeholders and reviewers can use it to gain a clear understanding of the service's capabilities and domain logic.
Note for Frontend Developers: While this document is valuable for understanding business logic and data interactions, please refer to the Service API Documentation for endpoint-level specifications and integration details.

Note for Backend Developers: Since the code for this service is automatically generated by Mindbricks, you typically won't need to implement or modify it manually. However, this document is especially valuable when you're building other services—whether within Mindbricks or externally—that need to interact with or depend on this service. It provides a clear reference to the service's data contracts, business rules, and API structure, helping ensure compatibility and correct integration.

ExpenseManagement Service Settings Edit
Handles CRUD for general business expenses (not tied to invoices), enforcing per-business tenant isolation, enabling categorization and supporting future reporting/analytics. Part of the FinTrack financial management backend.

Service Overview
This service is configured to listen for HTTP requests on port 3005, serving both the main API interface and default administrative endpoints.

The following routes are available by default:

API Test Interface (API Face): /
Swagger Documentation: /swagger
Postman Collection Download: /getPostmanCollection
Health Checks: /health and /admin/health
Current Session Info: /currentuser
Favicon: /favicon.ico
The service uses a PostgreSQL database for data storage, with the database name set to fintrack-expensemanagement-service.

This service is accessible via the following environment-specific URLs:

Preview: https://fintrack.prw.mindbricks.com/expensemanagement-api
Staging: https://fintrack-stage.mindbricks.co/expensemanagement-api
Production: https://fintrack.mindbricks.co/expensemanagement-api
Authentication & Security
Login Required: Yes
This service requires user authentication for access. It supports both JWT and RSA-based authentication mechanisms, ensuring secure user sessions and data integrity. If a crud route also is configured to require login, it will check a valid JWT token in the request query/header/bearer/cookie. If the token is valid, it will extract the user information from the token and make the fetched session data available in the request context.

Service Data Objects
The service uses a PostgreSQL database for data storage, with the database name set to fintrack-expensemanagement-service.

Data deletion is managed using a soft delete strategy. Instead of removing records from the database, they are flagged as inactive by setting the isActive field to false.

Object Name	Description	Public Access	Tenant Level
expense	Represents a general expense not tied to any invoice, always scoped to a single business. Can be categorized, linked (optionally) to a supplier, and used in future financial analysis. All fields support Unicode, amount is always in business-relevant currency.	accessProtected	Yes
expense Data Object
Object Overview
Description: Represents a general expense not tied to any invoice, always scoped to a single business. Can be categorized, linked (optionally) to a supplier, and used in future financial analysis. All fields support Unicode, amount is always in business-relevant currency.

This object represents a core data structure within the service and acts as the blueprint for database interaction, API generation, and business logic enforcement. It is defined using the ObjectSettings pattern, which governs its behavior, access control, caching strategy, and integration points with other systems such as Stripe and Redis.

Core Configuration
Soft Delete: Enabled — Determines whether records are marked inactive (isActive = false) instead of being physically deleted.
Public Access: accessProtected — If enabled, anonymous users may access this object’s data depending on API-level rules.
Tenant-Level Scope: Yes — Enables data isolation per tenant by attaching a tenant ID field.
Properties Schema
Property	Type	Required	Description
amount	Double	Yes	Expense amount (must be positive, required).
category	String	Yes	Expense category for grouping/filtering/reporting (e.g., "utilities", "travel"). Free text now, could migrate to a static data object in future.
currency	String	Yes	ISO currency code (e.g. 'USD'). Required for reporting, summaries, and multi-currency future support.
date	Date	Yes	Date the expense occurred. Required for reporting, sorting, and filtering.
description	String	Yes	Required human-readable description of the expense (e.g., purpose or detail).
notes	Text	No	Internal notes/justification—never exposed to public/customers. Optional.
supplierId	ID	No	Optional link to a known supplier. May be null/omitted for uncategorized/general expenses.
businessId	ID	Yes	An ID value to represent the tenant id of the business
Required properties are mandatory for creating objects and must be provided in the request body if no default value is set.
Default Values
Default values are automatically assigned to properties when a new object is created, if no value is provided in the request body. Since default values are applied on db level, they should be literal values, not expressions.If you want to use expressions, you can use transposed parameters in any business API to set default values dynamically.

amount: 0.0
category: 'default'
currency: 'default'
date: new Date()
description: 'default'
businessId: 00000000-0000-0000-0000-000000000000
Constant Properties
businessId

Constant properties are defined to be immutable after creation, meaning they cannot be updated or changed once set. They are typically used for properties that should remain constant throughout the object's lifecycle. A property is set to be constant if the Allow Update option is set to false.

Auto Update Properties
amount category currency date description notes supplierId

An update crud API created with the option Auto Params enabled will automatically update these properties with the provided values in the request body. If you want to update any property in your own business logic not by user input, you can set the Allow Auto Update option to false. These properties will be added to the update API's body parameters and can be updated by the user if any value is provided in the request body.

Elastic Search Indexing
amount category currency date description supplierId businessId

Properties that are indexed in Elastic Search will be searchable via the Elastic Search API. While all properties are stored in the elastic search index of the data object, only those marked for Elastic Search indexing will be available for search queries.

Database Indexing
amount category date supplierId businessId

Properties that are indexed in the database will be optimized for query performance, allowing for faster data retrieval. Make a property indexed in the database if you want to use it frequently in query filters or sorting.

Secondary Key Properties
businessId

Secondary key properties are used to create an additional indexed identifiers for the data object, allowing for alternative access patterns. Different than normal indexed properties, secondary keys will act as primary keys and Mindbricks will provide automatic secondary key db utility functions to access the data object by the secondary key.

Relation Properties
supplierId

Mindbricks supports relations between data objects, allowing you to define how objects are linked together. You can define relations in the data object properties, which will be used to create foreign key constraints in the database. For complex joins operations, Mindbricks supportsa BFF pattern, where you can view dynamic and static views based on Elastic Search Indexes. Use db level relations for simple one-to-one or one-to-many relationships, and use BFF views for complex joins that require multiple data objects to be joined together.

supplierId: ID Relation to supplier.id
The target object is a parent object, meaning that the relation is a one-to-many relationship from target to this object.

On Delete: Set Null Required: No

Filter Properties
amount category currency date description supplierId businessId

Filter properties are used to define parameters that can be used in query filters, allowing for dynamic data retrieval based on user input or predefined criteria. These properties are automatically mapped as API parameters in the listing API's that have "Auto Params" enabled.

amount: Double has a filter named amount

category: String has a filter named category

currency: String has a filter named currency

date: Date has a filter named date

description: String has a filter named description

supplierId: ID has a filter named supplierId

businessId: ID has a filter named businessId

Business Logic
expenseManagement has got 6 Business APIs to manage its internal and crud logic. For the details of each business API refer to its chapter.

Create Expense

Delete Expense

Get Expense

List Expenses

Update Expense

_fetch Listexpense

Edge Controllers
m2mCreateExpense
Configuration:

Function Name: m2mCreateExpense
Login Required: No
REST Settings:

Path: /m2m/expense/create
Method:
m2mBulkCreateExpense
Configuration:

Function Name: m2mBulkCreateExpense
Login Required: No
REST Settings:

Path: /m2m/expense/bulk-create
Method:
m2mUpdateExpenseById
Configuration:

Function Name: m2mUpdateExpenseById
Login Required: No
REST Settings:

Path: /m2m/expense/update/:id
Method:
m2mDeleteExpenseById
Configuration:

Function Name: m2mDeleteExpenseById
Login Required: No
REST Settings:

Path: /m2m/expense/delete/:id
Method:
m2mUpdateExpenseByQuery
Configuration:

Function Name: m2mUpdateExpenseByQuery
Login Required: No
REST Settings:

Path: /m2m/expense/update-by-query
Method:
m2mDeleteExpenseByQuery
Configuration:

Function Name: m2mDeleteExpenseByQuery
Login Required: No
REST Settings:

Path: /m2m/expense/delete-by-query
Method:
m2mUpdateExpenseByIdList
Configuration:

Function Name: m2mUpdateExpenseByIdList
Login Required: No
REST Settings:

Path: /m2m/expense/update-by-id-list
Method:
Service Library
Functions
No general functions defined.

Hook Functions
No hook functions defined.

Edge Functions
m2mCreateExpense.js
module.exports = async (request) => {
        const { createExpense } = require("dbLayer");
        const context = { session: request.session, requestId: request.requestId };
        const data = request.body?.data || request.data || request;
        const result = await createExpense(data, context);
        return { status: 200, content: result };
      }
m2mBulkCreateExpense.js
module.exports = async (request) => {
        const { createBulkExpense } = require("dbLayer");
        const context = { session: request.session, requestId: request.requestId };
        const dataList = request.body?.dataList || request.dataList || (Array.isArray(request.body) ? request.body : [request.body]);
        if (!Array.isArray(dataList) || dataList.length === 0) {
          return { status: 400, message: "dataList must be a non-empty array" };
        }
        const result = await createBulkExpense(dataList, context);
        return { status: 200, content: result };
      }
m2mUpdateExpenseById.js
module.exports = async (request) => {
        const { updateExpenseById } = require("dbLayer");
        const context = { session: request.session, requestId: request.requestId };
        const id = request.body?.id || request.params?.id || request.id;
        const dataClause = request.body?.dataClause || request.dataClause || request.body;
        if (dataClause && dataClause.id) delete dataClause.id;
        if (!id) {
          return { status: 400, message: "ID is required" };
        }
        const result = await updateExpenseById(id, dataClause, context);
        return { status: 200, content: result };
      }
m2mDeleteExpenseById.js
module.exports = async (request) => {
        const { deleteExpenseById } = require("dbLayer");
        const context = { session: request.session, requestId: request.requestId };
        const id = request.body?.id || request.params?.id || request.id;
        if (!id) {
          return { status: 400, message: "ID is required" };
        }
        const result = await deleteExpenseById(id, context);
        return { status: 200, content: result };
      }
m2mUpdateExpenseByQuery.js
module.exports = async (request) => {
        const { updateExpenseByQuery } = require("dbLayer");
        const context = { session: request.session, requestId: request.requestId };
        const dataClause = request.body?.dataClause || request.dataClause || request.body;
        const query = request.body?.query || request.query || {};
        if (!query || typeof query !== "object" || Object.keys(query).length === 0) {
          return { status: 400, message: "Query is required and must be a non-empty object" };
        }
        const result = await updateExpenseByQuery(dataClause, query, context);
        return { status: 200, content: result };
      }
m2mDeleteExpenseByQuery.js
module.exports = async (request) => {
        const { deleteExpenseByQuery } = require("dbLayer");
        const context = { session: request.session, requestId: request.requestId };
        const query = request.body?.query || request.query || {};
        if (!query || typeof query !== "object" || Object.keys(query).length === 0) {
          return { status: 400, message: "Query is required and must be a non-empty object" };
        }
        const result = await deleteExpenseByQuery(query, context);
        return { status: 200, content: result };
      }
m2mUpdateExpenseByIdList.js
module.exports = async (request) => {
        const { updateExpenseByIdList } = require("dbLayer");
        const context = { session: request.session, requestId: request.requestId };
        const idList = request.body?.idList || request.idList || [];
        const dataClause = request.body?.dataClause || request.dataClause || request.body;
        if (dataClause && dataClause.idList) delete dataClause.idList;
        if (!Array.isArray(idList) || idList.length === 0) {
          return { status: 400, message: "idList must be a non-empty array" };
        }
        const result = await updateExpenseByIdList(idList, dataClause, context);
        return { status: 200, content: result };
      }
Templates
No templates defined.

Assets
No assets defined.

Public Assets
No public assets defined.

Event Emission
Integration Patterns
Deployment Considerations
Environment Configuration
HTTP Port: 3005
Database Type: MongoDB
Global Soft Delete: Enabled
Implementation Guidelines
Development Workflow
Data Model Implementation: Generate database schema from data object definitions
CRUD Route Generation: Implement auto-generated routes with custom logic
Custom Logic Integration: Implement hook functions and edge functions
Authentication Integration: Configure with project-level authentication
Testing: Unit and integration testing for all components
Code Generation Expectations
Database Schema: Auto-generated from data objects and relationships
API Routes: REST endpoints with customizable behavior
Validation Logic: Input validation from property definitions
Access Control: Authentication and authorization middleware
Custom Code Integration Points
Hook Functions: Lifecycle-specific custom logic
Edge Functions: Full request/response control
Library Functions: Reusable business logic
Templates: Dynamic content rendering
Testing Strategy
Unit Testing
Test all custom library functions
Test validation logic and business rules
Test hook function implementations
Integration Testing
Test API endpoints with authentication scenarios
Test database operations and transactions
Test external integrations
Test event emission and Kafka integration
Performance Testing
Load test high-traffic endpoints
Test caching effectiveness
Monitor database query performance
Test scalability under load
Appendices
Data Type Reference
Type	Description	Storage
ID	Unique identifier	UUID (SQL) / ObjectID (NoSQL)
String	Short text (≤255 chars)	VARCHAR
Text	Long-form text	TEXT
Integer	32-bit whole numbers	INT
Boolean	True/false values	BOOLEAN
Double	64-bit floating point	DOUBLE
Float	32-bit floating point	FLOAT
Short	16-bit integers	SMALLINT
Object	JSON object	JSONB (PostgreSQL) / Object (MongoDB)
Date	ISO 8601 timestamp	TIMESTAMP
Enum	Fixed numeric values	SMALLINT with lookup
Enum Value Mappings
Request Locations
0: Bearer token in Authorization header
1: Cookie value
2: Custom HTTP header
3: Query parameter
4: Request body property
5: URL path parameter
6: Session data
7: Root request object
HTTP Methods
0: GET
1: POST
2: PUT
3: PATCH
4: DELETE
Edge Function Signature
async function edgeFunction(request) {
  // Custom request processing
  // Return response object or throw error
  return {
    data: {},
    status: 200,
    message: "Success"
  };
}